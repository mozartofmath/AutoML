{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b2072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b3a512",
   "metadata": {},
   "source": [
    "## Parse Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba940b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_shape(line):\n",
    "    counts = []\n",
    "    current_count = 0\n",
    "    state = 0\n",
    "    for c in line:\n",
    "        if state == 0:\n",
    "            if c == \"{\":\n",
    "                state = 1\n",
    "        else:\n",
    "            if c == ',':\n",
    "                current_count+=1\n",
    "            elif c == \"}\":\n",
    "                state = 0\n",
    "                counts.append(current_count+1)\n",
    "                current_count = 0\n",
    "    return counts\n",
    "\n",
    "def parse_inputs(input_path, output_path):\n",
    "    input_, output_ = open(input_path, 'r'), open(output_path, 'r')\n",
    "    X, y = [],[]\n",
    "    for line in input_.readlines():\n",
    "        l = [float(c) for c in line.strip().replace('{','').replace('}','').split(',')]\n",
    "        X.append(l)\n",
    "    #print(line)\n",
    "    for line in output_.readlines():\n",
    "        l = [float(c) for c in line.strip().replace('{','').replace('}','').split(',')]\n",
    "        y.append(l)\n",
    "    #print(line)\n",
    "    return X, y, output_shape(line)\n",
    "\n",
    "def format_output(vals, out_shape):\n",
    "    strings = []\n",
    "    for i in range(len(out_shape)):\n",
    "        strings.append('{' + \",\".join(vals[sum(out_shape[:i]):sum(out_shape[:i+1])]) + '}')\n",
    "    return ','.join(strings)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da41dc",
   "metadata": {},
   "source": [
    "## Detect Problem Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53748839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_problem_type(y):\n",
    "#     if y.shape[-1] == 1:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32ee2a0",
   "metadata": {},
   "source": [
    "## ML Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df2c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_block(block_input, n_layers, n_units, activation = 'relu'):\n",
    "    block_output = tf.keras.layers.Dense(n_units, activation=activation)(block_input)\n",
    "    for i in range(n_layers-1):\n",
    "        block_output = tf.keras.layers.Dense(n_units, activation=activation)(block_output)\n",
    "    return block_output\n",
    "\n",
    "def conv_block(block_input, n_layers, n_filters, filter_size, stride, activation = 'relu'):\n",
    "    block_output = tf.keras.layers.Conv2D(n_filters, \n",
    "                                          filter_size, \n",
    "                                          strides=(stride, stride), \n",
    "                                          activation=activation)(block_input)\n",
    "    for i in range(n_layers-1):\n",
    "        block_output = tf.keras.layers.Conv2D(n_filters, \n",
    "                                              filter_size, \n",
    "                                              strides=(stride, stride), \n",
    "                                              activation=activation)(block_output)\n",
    "    block_output = tf.keras.layers.MaxPooling2D((2,2), strides=(2,2))(block_output)\n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bfa4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(X, y, problem_type):\n",
    "    loss, optimizer, metrics = 'mse', 'adam', 'accuracy'\n",
    "    inputs = tf.keras.layers.Input(shape=X.shape[1:])\n",
    "    \n",
    "    dense_out = dense_block(inputs, n_layers=1, n_units=X.shape[-1]*2, activation = 'relu')\n",
    "    dense_out = dense_block(inputs, n_layers=2, n_units=X.shape[-1]*4, activation = 'relu')\n",
    "    dense_out = dense_block(inputs, n_layers=1, n_units=X.shape[-1], activation = 'relu')\n",
    "    \n",
    "    if problem_type[0] == 'classification':\n",
    "        outputs = tf.keras.layers.Dense(y.shape[-1], activation='sigmoid')(dense_out)\n",
    "        loss = 'binary_crossentropy'\n",
    "        metrics = 'mse'\n",
    "    \n",
    "    elif problem_type[0] == 'regression':\n",
    "        outputs = tf.keras.layers.Dense(y.shape[-1])(dense_out)\n",
    "        loss = 'mse'\n",
    "        metrics = 'mse'\n",
    "    model = tf.keras.Model(inputs = inputs, outputs = outputs)\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=[metrics])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b47d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, y, epochs):\n",
    "    train_mask = [random.randint(0,9)<1 for i in range(len(X))]\n",
    "    test_mask = [not b for b in train_mask]\n",
    "    X_train, y_train = X[train_mask,:], y[train_mask,:]\n",
    "    X_test, y_test = X[test_mask,:], y[test_mask,:]\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_test, y_test), batch_size=10)\n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50066e1",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e77ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(f\"Arguments count: {len(sys.argv)}\")\n",
    "#     for i, arg in enumerate(sys.argv):\n",
    "#         print(f\"Argument {i:>6}: {arg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8967ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def automl():\n",
    "    file = open('config.json', 'r')\n",
    "    config = json.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    mode = config['mode']\n",
    "    \n",
    "    if mode == 'train':\n",
    "        input_path = config['train']['input_path']\n",
    "        output_path = config['train']['output_path']\n",
    "        model_path = config['train']['model_path']\n",
    "        \n",
    "        X, y, out_shape = parse_inputs(input_path, output_path)\n",
    "        X, y, out_shape = np.array(X), np.array(y), np.array(out_shape).astype(str)\n",
    "        model = generate_model(X, y, ['regression', 0])\n",
    "        history = train_model(model, X, y, epochs = 1)\n",
    "        model.save(model_path)\n",
    "        \n",
    "        model_metadata_path = model_path[:-3]+'_metadata.json'\n",
    "        file = open(model_metadata_path, 'w')\n",
    "        file.write('{\"out_shape\" : [' + \",\".join(out_shape)+ ']}')\n",
    "        file.close()\n",
    "        \n",
    "    if mode == 'predict':\n",
    "        input_path = config['predict']['input_path']\n",
    "        output_path = config['predict']['output_path']\n",
    "        model_path = config['predict']['model_path']\n",
    "        \n",
    "        model_metadata_path = model_path[:-3]+'_metadata.json'\n",
    "        \n",
    "        X, _, _ = parse_inputs(input_path, input_path)\n",
    "        X = np.array(X)\n",
    "        \n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        \n",
    "        pred = (model.predict(X) > 0.5).astype(int).astype(str)\n",
    "        \n",
    "        metadata_file = open(model_metadata_path, 'r')\n",
    "        metadata = json.load(metadata_file)\n",
    "        metadata_file.close()\n",
    "        out_shape = metadata['out_shape']\n",
    "        \n",
    "        out_file = open(output_path, 'w')\n",
    "        for row in pred:\n",
    "            out_file.write(format_output(row, out_shape) +'\\n')\n",
    "        out_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6309a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c06af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "','.join(['1','1','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be026bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Models/model_1.h5'\n",
    "model_metadata_path = model_path[:-3]+'_metadata.json'\n",
    "file = open(model_metadata_path, 'w')\n",
    "file.write('{\"out_shape\" : [' + \",\".join([\"1\",\"1\",\"1\"])+ ']}')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a2877",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1.0,2.0,3.0]).astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"{0,1,2,5},{0,1,1,1,1}\"\n",
    "\n",
    "def output_shape(line):\n",
    "    counts = []\n",
    "    current_count = 0\n",
    "    state = 0\n",
    "    for c in line:\n",
    "        if state == 0:\n",
    "            if c == \"{\":\n",
    "                state = 1\n",
    "        else:\n",
    "            if c == ',':\n",
    "                current_count+=1\n",
    "            elif c == \"}\":\n",
    "                state = 0\n",
    "                counts.append(current_count+1)\n",
    "                current_count = 0\n",
    "    return counts\n",
    "output_shape(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862da47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [1,2,3]\n",
    "vals = ['1','2','3','4','5','6']\n",
    "strings = []\n",
    "for i in range(len(shape)):\n",
    "    strings.append('{' + \",\".join(vals[sum(shape[:i]):sum(shape[:i+1])]) + '}')\n",
    "','.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f15a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "format_output(['1','2','3','4','5','6'], [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3656d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('config.json', 'r')\n",
    "config = json.load(file)\n",
    "\n",
    "X, y = parse_inputs('TrainingFiles/input_56.txt', 'TrainingFiles/output_56.txt')\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = generate_model(X, y, ['regression', 0])\n",
    "history = train_model(model1, X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs((model1.predict(X) > 0.5).astype(int) - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b761a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = generate_model(X, y, ['classification', 1])\n",
    "history = train_model(model2, X, y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(abs((model2.predict(X) > 0.5).astype(int) - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87094088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
